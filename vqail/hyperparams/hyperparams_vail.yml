# Tuned (Fast VM)
Pendulum-v0:
  n_envs: 4
  total_timesteps: !!float 1500
  lr_schedule_main: True
  lr_schedule_agent: False
  learning_rate: !!float 3e-4
  policy_kwargs: "{'policy': 'MlpPolicy',
                   'verbose': 1,
                   'n_steps': 512,
                   'batch_size': 64,
                   'gae_lambda': 0.99,
                   'gamma': 0.99,
                   'ent_coef': 1e-3,
                   'learning_rate': 3e-4,
                   'n_epochs': 10,
                   'clip_range': 0.2,
                   'target_kl': 0.01,
                  }"
  vail: "{'hidden_size': 64,
          'latent_size': 3}"

# Tuned (Fast VM)
CartPole-v1:
  n_envs: 4
  total_timesteps: !!float 300
  learning_rate: !!float 3e-4
  policy_kwargs: "{'policy': 'MlpPolicy',
                   'verbose': 1,
                   'n_steps': 512,
                   'learning_rate': 3e-4,
                   'batch_size': 64,
                   'n_epochs': 10
                  }"
  vail: "{'hidden_size': 8,
          'latent_size': 2}"

# Tuned (Fast VM)
Acrobot-v1:
  n_envs: 4
  norm_obs: True
  total_timesteps: !!float 2500
  learning_rate: !!float 3e-3
  lr_schedule_main: True
  lr_schedule_agent: True
  ent_decay: 0.999
  policy_kwargs: "{'policy': 'MlpPolicy',
                   'verbose': 1,
                   'n_steps': 512,
                   'gamma': 0.99,
                   'gae_lambda': 0.95,
                   'learning_rate': 3e-3,
                   'ent_coef': 0.2,
                   'n_epochs': 10,
                   'target_kl': 0.01,
                   }"
  vail: "{'hidden_size': 100,
          'latent_size': 3}"

# Tuned (Fast VM)
Hopper-v2:
  norm_obs: False
  n_envs: 4
  total_timesteps: !!float 1200
  learning_rate: !!float 3e-4
  policy_kwargs: "{'policy': 'MlpPolicy',
                   'verbose': 1,
                   'n_steps': 1024,
                   'learning_rate': 3e-4,
                   'gamma': 0.99,
                   'ent_coef': 0.0,
                   'gae_lambda': 0.97,
                   'n_epochs': 10,
                   'sde_sample_freq': 4,
                   'max_grad_norm': 0.5,
                   'use_sde': True,
                   'clip_range': 0.4,
                   'vf_coef': 0.5,
                   'batch_size': 64,
                   'policy_kwargs': {
                                      'log_std_init': -1,
                                      'net_arch': [dict(pi=[256, 256], vf=[256, 256])]
                                    }
                  }"
  vail: "{'hidden_size': 100,
          'latent_size': 3}"

# Tuned (Fast VM)
HalfCheetah-v2:
  norm_obs: False
  n_envs: 4
  total_timesteps: !!float 1200
  learning_rate: !!float 3e-4
  policy_kwargs: "{'policy': 'MlpPolicy',
                   'verbose': 1,
                   'n_steps': 1024,
                   'learning_rate': 1e-4,
                   'gamma': 0.99,
                   'ent_coef': 0.0,
                   'gae_lambda': 0.97,
                   'n_epochs': 10,
                   'sde_sample_freq': 4,
                   'max_grad_norm': 0.5,
                   'use_sde': True,
                   'clip_range': 0.4,
                   'vf_coef': 0.5,
                   'batch_size': 128,
                   'policy_kwargs': {
                                      'log_std_init': -1,
                                      'net_arch': [dict(pi=[256, 256], vf=[256, 256])]
                                    }
                  }"
  vail: "{'hidden_size': 100,
          'latent_size': 3}"

FetchPickAndPlace-v1:
  time_limit: False
  mujoco_img: True
  obs_only: True
  n_envs: 8
  total_timesteps: !!float 1200
  reward_factor: -1
  learning_rate: !!float 3e-3
  policy_kwargs: "{'policy': 'CnnPolicy',
                   'verbose': 1,
                   'n_steps': 256,
                   'learning_rate': 3e-4,
                   'gamma': 0.99,
                   'ent_coef': 0.2,
                   'gae_lambda': 0.95,
                   'n_epochs': 10,
                   'clip_range': 0.2,
                   'vf_coef': 0.5,
                   'batch_size': 32,
                  }"
  vail: "{'hidden_size': 100,
          'latent_size': 3}"

# Tuned (Colab)
MiniGrid-Empty-Random-6x6-v0:
  mini_grid: True
  obs_only: True
  tile_size: 8
  gail_loss: 'agent'
  n_envs: 2
  total_timesteps: !!float 250
  reward_factor: 1
  learning_rate: !!float 3e-4
  ent_decay: 1.0
  policy_kwargs: "{'policy': 'CnnPolicy',
                   'verbose': 1,
                   'n_steps': 128,
                   'batch_size': 32,
                   'learning_rate': 3e-4,
                   'n_epochs': 2,
                   'ent_coef': 0.1,
                   'clip_range': 0.1,
                   'gamma': 0.99
                  }"
  vail: "{'hidden_size': 256,
          'latent_size': 3}"

# Tuned (Colab)
MiniGrid-Empty-8x8-v0:
  mini_grid: True
  obs_only: True
  tile_size: 8
  n_envs: 2
  total_timesteps: !!float 200
  reward_factor: 1
  learning_rate: !!float 0.0001221 
  lr_schedule_main: False
  lr_schedule_agent: False
  ent_decay: 1.0
  # ent_coef: 0.0 for true reward
  policy_kwargs: "{'policy': 'CnnPolicy',
                   'verbose': 1,
                   'n_steps': 256,
                   'batch_size': 64,
                   'learning_rate': 3e-4,
                   'n_epochs': 4,
                   'ent_coef': 0.001308,
                   'clip_range': 0.2,
                   'gamma': 0.99
                  }"
  vail: "{'hidden_size': 256,
          'latent_size': 3}"

MiniGrid-DoorKey-5x5-v0:
  mini_grid: True
  obs_only: True
  tile_size: 10
  gail_loss: 'agent'
  n_envs: 8
  total_timesteps: !!float 250
  reward_factor: 1
  learning_rate: !!float 3e-4
  ent_decay: 1.0
  policy_kwargs: "{'policy': 'CnnPolicy',
                   'verbose': 1,
                   'n_steps': 128,
                   'batch_size': 32,
                   'learning_rate': 3e-4,
                   'n_epochs': 2,
                   'ent_coef': 0.1,
                   'clip_range': 0.1,
                   'gamma': 0.99
                  }"
  vail: "{'hidden_size': 256,
          'latent_size': 3}"



MiniGrid-DoorKey-8x8-v0:
  mini_grid: True
  obs_only: True
  tile_size: 10
  gail_loss: 'agent'
  n_envs: 8
  total_timesteps: !!float 250
  reward_factor: 1
  learning_rate: !!float 3e-4
  ent_decay: 1.0
  policy_kwargs: "{'policy': 'CnnPolicy',
                   'verbose': 1,
                   'n_steps': 128,
                   'batch_size': 32,
                   'learning_rate': 3e-4,
                   'n_epochs': 2,
                   'ent_coef': 0.1,
                   'clip_range': 0.1,
                   'gamma': 0.99
                  }"
  vail: "{'hidden_size': 256,
          'latent_size': 3}"



MiniGrid-RedBlueDoors-6x6-v0:
  mini_grid: True
  obs_only: True
  tile_size: 6
  gail_loss: 'agent'
  n_envs: 8
  total_timesteps: !!float 250
  reward_factor: 1
  learning_rate: !!float 3e-4
  ent_decay: 1.0
  policy_kwargs: "{'policy': 'CnnPolicy',
                   'verbose': 1,
                   'n_steps': 128,
                   'batch_size': 32,
                   'learning_rate': 3e-4,
                   'n_epochs': 2,
                   'ent_coef': 0.1,
                   'clip_range': 0.1,
                   'gamma': 0.99
                  }"
  vail: "{'hidden_size': 256,
          'latent_size': 3}"

# Tuned (Azure VM)
# default: n_embed=32, embed_dim=16
MiniWorld-OneRoom-v0:
  obs_only: True
  n_envs: 8
  frame_stack: 4
  total_timesteps: !!float 600
  reward_factor: 1
  learning_rate: !!float 1e-4
  lr_schedule_main: False
  lr_schedule_agent: False
  ent_decay: 1.0
  policy_kwargs: "{'policy': 'CnnPolicy',
                   'verbose': 1,
                   'n_steps': 256,
                   'batch_size': 128,
                   'learning_rate': 5e-5,
                   'n_epochs': 10,
                   'ent_coef': 0.01,
                   'clip_range': 0.2,
                   'gamma': 0.99,
                   'gae_lambda': 0.97,
                  }"
  vail: "{'hidden_size': 100,
          'latent_size': 3}"

# Tuned (Azure VM)
MiniWorld-Hallway-v0:
  obs_only: True
  n_envs: 8
  frame_stack: 4
  total_timesteps: !!float 600
  reward_factor: 1
  learning_rate: !!float 3e-4
  lr_schedule_main: False
  lr_schedule_agent: False
  ent_decay: 1.0
  policy_kwargs: "{'policy': 'CnnPolicy',
                   'verbose': 1,
                   'n_steps': 256,
                   'batch_size': 64,
                   'learning_rate': 3e-4,
                   'n_epochs': 10,
                   'ent_coef': 0.01,
                   'clip_range': 0.2,
                   'gamma': 0.99,
                   'gae_lambda': 0.97,
                  }"
  vail: "{'hidden_size': 100,
          'latent_size': 3}"

# Tuned (Azure VM)
# n_embeddings changed 32 to 256 for test
MiniWorld-TMaze-v0:
  obs_only: True
  n_envs: 8
  frame_stack: 4
  total_timesteps: !!float 800
  reward_factor: 1
  learning_rate: !!float 1e-4
  lr_schedule_main: False
  lr_schedule_agent: False
  ent_decay: 1.0
  policy_kwargs: "{'policy': 'CnnPolicy',
                   'verbose': 1,
                   'n_steps': 1024,
                   'batch_size': 128,
                   'learning_rate': 5e-5,
                   'n_epochs': 10,
                   'ent_coef': 0.01,
                   'clip_range': 0.2,
                   'gamma': 0.99,
                   'gae_lambda': 0.97,
                  }"
  vail: "{'hidden_size': 128,
          'latent_size': 3}"

# Tuned (Colab)
MiniWorld-YMaze-v0:
  obs_only: True
  n_envs: 8
  frame_stack: 4
  total_timesteps: !!float 1500
  reward_factor: 1
  learning_rate: !!float 1e-4
  lr_schedule_main: False
  lr_schedule_agent: False
  ent_decay: 1.0
  policy_kwargs: "{'policy': 'CnnPolicy',
                   'verbose': 1,
                   'n_steps': 1024,
                   'batch_size': 128,
                   'learning_rate': 5e-5,
                   'n_epochs': 10,
                   'ent_coef': 0.01,
                   'clip_range': 0.2,
                   'gamma': 0.99,
                   'gae_lambda': 0.97,
                  }"
  vail: "{'hidden_size': 100,
          'latent_size': 3}"

# Tuned (Colab)
MiniWorld-TMazeRight-v0:
  obs_only: True
  n_envs: 8
  frame_stack: 4
  total_timesteps: !!float 1200
  reward_factor: 1
  learning_rate: !!float 1e-4
  lr_schedule_main: False
  lr_schedule_agent: False
  ent_decay: 1.0
  policy_kwargs: "{'policy': 'CnnPolicy',
                   'verbose': 1,
                   'n_steps': 512,
                   'batch_size': 128,
                   'learning_rate': 5e-5,
                   'n_epochs': 10,
                   'ent_coef': 0.01,
                   'clip_range': 0.2,
                   'gamma': 0.99,
                   'gae_lambda': 0.97,
                  }"
  vail: "{'hidden_size': 128,
          'latent_size': 64}"

# Tuned (Colab)
MiniWorld-TMazeLeft-v0:
  obs_only: True
  n_envs: 16
  frame_stack: 4
  total_timesteps: !!float 1500
  reward_factor: 1
  learning_rate: !!float 1e-4
  lr_schedule_main: False
  lr_schedule_agent: False
  ent_decay: 1.0
  policy_kwargs: "{'policy': 'CnnPolicy',
                   'verbose': 1,
                   'n_steps': 512,
                   'batch_size': 128,
                   'learning_rate': 5e-5,
                   'n_epochs': 10,
                   'ent_coef': 0.01,
                   'clip_range': 0.2,
                   'gamma': 0.99,
                   'gae_lambda': 0.97,
                  }"
  vail: "{'hidden_size': 128,
          'latent_size': 3}"

MiniWorld-PickupObjs-v0:
  obs_only: True
  n_envs: 16
  frame_stack: 4
  total_timesteps: !!float 3000
  reward_factor: -1
  learning_rate: !!float 1e-3
  lr_schedule_main: True
  lr_schedule_agent: True
  ent_decay: 0.995
  policy_kwargs: "{'policy': 'CnnPolicy',
                   'verbose': 1,
                   'n_steps': 512,
                   'batch_size': 128,
                   'learning_rate': 3e-4,
                   'n_epochs': 10,
                   'ent_coef': 0.01,
                   'clip_range': 0.2,
                   'gamma': 0.99,
                   'gae_lambda': 0.95,
                  }"
  vail: "{'hidden_size': 128,
          'latent_size': 3}"

BreakoutNoFrameskip-v4:
  obs_only: True
  n_envs: 8
  atari: True
  frame_stack: 4
  total_timesteps: !!float 2500
  learning_rate: !!float 3e-4
  policy_kwargs: "{'policy': 'MlpPolicy',
                   'verbose': 1,
                   'n_steps': 128,
                   'batch_size': 256,
                   'ent_coef': 0.01,
                   'learning_rate': 2.5e-4,
                   'n_epochs': 4,
                   'clip_range': 0.1,
                  }"
  vail: "{'discrim_hidden_size': 256}"

PongNoFrameskip-v4:
  obs_only: True
  n_envs: 8
  atari: True
  frame_stack: 4
  total_timesteps: !!float 2500
  learning_rate: !!float 3e-4
  policy_kwargs: "{'policy': 'MlpPolicy',
                   'verbose': 1,
                   'n_steps': 128,
                   'batch_size': 256,
                   'ent_coef': 0.01,
                   'learning_rate': 2.5e-4,
                   'n_epochs': 4,
                   'clip_range': 0.1,
                  }"
  vail: "{'discrim_hidden_size': 256}"
